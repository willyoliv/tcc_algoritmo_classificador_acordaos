{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d92843d",
   "metadata": {},
   "source": [
    "### Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c9dbcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Acordao:\n",
    "    def __init__(self, ementa, assunto):\n",
    "        self.ementa = ementa\n",
    "        self.assunto = assunto\n",
    "        \n",
    "class AcordaoContainer:\n",
    "    def __init__(self, acordaos):\n",
    "        self.acordaos = acordaos\n",
    "    \n",
    "    def get_x(self, vectorizer):\n",
    "        return vectorizer.transform(self.get_ementa())\n",
    "    \n",
    "    def get_ementa(self):\n",
    "        return [x.ementa for x in self.acordaos]\n",
    "    \n",
    "    def get_assunto(self):\n",
    "        return [x.assunto for x in self.acordaos]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e6e8d4",
   "metadata": {},
   "source": [
    "### Funções para tratamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa8169ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removerStopWords(ementas):\n",
    "    nlp = spacy.load('pt_core_news_lg')\n",
    "    textos = []\n",
    "    for texto in ementas:\n",
    "        texto = re.sub(u'[^a-zA-Z0-9áéíóúÁÉÍÓÚâêîôÂÊÎÔãõÃÕçÇ: ]', ' ', texto)\n",
    "        doc = nlp(texto)\n",
    "        text_aux = []\n",
    "        for token in doc:\n",
    "            if token.is_stop == False and token.is_digit == False and token.is_space == False and token.like_num == False:\n",
    "                text_aux.append(token.text.lower()) \n",
    "        textos.append(\" \".join(text_aux))\n",
    "    return textos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb32d22",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73e252dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, recall_score, recall_score, precision_score, accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from joblib import dump, load\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675e06a2",
   "metadata": {},
   "source": [
    "### Carregando dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d4da632",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DESPESA                104\n",
      "PROCESSUAL              99\n",
      "LICITACAO               97\n",
      "PESSOAL                 94\n",
      "OUTROS                  84\n",
      "PRESTACAO DE CONTAS     72\n",
      "CONTRATO                68\n",
      "PREVIDENCIA             56\n",
      "AGENTE POLITICO         49\n",
      "RESPONSABILIDADE        38\n",
      "Name: assunto_agrupado, dtype: int64\n",
      "DESPESA                26\n",
      "LICITACAO              25\n",
      "PROCESSUAL             25\n",
      "PESSOAL                24\n",
      "OUTROS                 22\n",
      "PRESTACAO DE CONTAS    19\n",
      "CONTRATO               18\n",
      "PREVIDENCIA            14\n",
      "AGENTE POLITICO        13\n",
      "RESPONSABILIDADE       10\n",
      "Name: assunto_agrupado, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Dados pra treino\n",
    "acordaosTrain = []\n",
    "ementasTrain = []\n",
    "assuntosTrain = []\n",
    "dataTrain = pd.read_csv (r'C:\\Users\\willy.silva\\Desktop\\tcc_algoritmo_classificador_acordaos\\Dados\\decisoes_com_dados_adicionais_train.csv', sep=\";\")   \n",
    "dfTrain = pd.DataFrame(dataTrain, columns= ['ementa','assunto_agrupado'])\n",
    "ementasTrain = dfTrain['ementa'].apply(lambda x: np.str_(x))\n",
    "assuntosTrain = dfTrain['assunto_agrupado'].apply(lambda x: np.str_(x))\n",
    "print(dfTrain['assunto_agrupado'].value_counts())\n",
    "\n",
    "# Dados pra teste\n",
    "acordaosTest = []\n",
    "ementasTest = []\n",
    "assuntosTest = []\n",
    "dataTest = pd.read_csv (r'C:\\Users\\willy.silva\\Desktop\\tcc_algoritmo_classificador_acordaos\\Dados\\decisoes_com_dados_adicionais_test.csv', sep=\";\")   \n",
    "dfTest = pd.DataFrame(dataTest, columns= ['ementa','assunto_agrupado'])\n",
    "ementasTest = dfTest['ementa'].apply(lambda x: np.str_(x))\n",
    "assuntosTest = dfTest['assunto_agrupado'].apply(lambda x: np.str_(x))\n",
    "print(dfTest['assunto_agrupado'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60534720",
   "metadata": {},
   "outputs": [],
   "source": [
    "ementasLimpasTrain = removerStopWords(ementasTrain)\n",
    "for i in range(0,len(ementasTrain)):\n",
    "    acordaosTrain.append(Acordao(ementasLimpasTrain[i],assuntosTrain[i]))\n",
    "\n",
    "ementasLimpasTest = removerStopWords(ementasTest)\n",
    "for i in range(0,len(ementasTest)):\n",
    "    acordaosTest.append(Acordao(ementasLimpasTest[i],assuntosTest[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcf8392",
   "metadata": {},
   "source": [
    "### Separando os dados para treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "510a756f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_container = AcordaoContainer(acordaosTrain)\n",
    "test_container = AcordaoContainer(acordaosTest)\n",
    "\n",
    "corpus = train_container.get_ementa()\n",
    "vectorizer = TfidfVectorizer(max_features=1500, min_df=5, max_df=0.7)\n",
    "vectorizer.fit(corpus)\n",
    "\n",
    "#array para treinamento do modelo \n",
    "train_x = train_container.get_x(vectorizer)\n",
    "train_y = train_container.get_assunto()\n",
    "#array para teste do modelo\n",
    "test_x = test_container.get_x(vectorizer)\n",
    "test_y = test_container.get_assunto()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347ed47b",
   "metadata": {},
   "source": [
    "### Criando modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53ba8fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM SVC\n",
    "svm_model = svm.SVC(C=16, kernel='linear', gamma='auto', probability=True)\n",
    "svm_model.fit(train_x, train_y)\n",
    "\n",
    "# Naive Bayes\n",
    "nv_model = MultinomialNB()\n",
    "nv_model.fit(train_x, train_y)\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "rf_model.fit(train_x, train_y) \n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "663dbdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valor real LICITACAO\n",
      "predição [[0.00979941 0.01924559 0.20377699 0.44290259 0.06620563 0.20435873\n",
      "  0.01059414 0.02217774 0.00894164 0.01199754]]\n",
      "['AGENTE POLITICO' 'CONTRATO' 'DESPESA' 'LICITACAO' 'OUTROS' 'PESSOAL'\n",
      " 'PRESTACAO DE CONTAS' 'PREVIDENCIA' 'PROCESSUAL' 'RESPONSABILIDADE']\n",
      "valor real LICITACAO\n",
      "predição ['LICITACAO']\n",
      "valor real LICITACAO\n",
      "predição ['PESSOAL']\n",
      "valor real LICITACAO\n",
      "predição ['LICITACAO']\n"
     ]
    }
   ],
   "source": [
    "print(\"valor real \"+test_y[1])\n",
    "print(\"predição\",svm_model.predict_proba(test_x[1]))\n",
    "print(svm_model.classes_)\n",
    "print(\"valor real \"+test_y[1])\n",
    "print(\"predição\", nv_model.predict(test_x[1]))\n",
    "print(\"valor real \"+test_y[1])\n",
    "print(\"predição\",rf_model.predict(test_x[1]))\n",
    "print(\"valor real \"+test_y[1])\n",
    "print(\"predição\", lr_model.predict(test_x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a423e8",
   "metadata": {},
   "source": [
    "### Testando os modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa35b8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "F1 score: 0.8764236913838859\n",
      "Recall score: 0.8775510204081632\n",
      "Precision score: 0.8777501048197588\n",
      "Accuracy score: 0.8775510204081632 \n",
      "\n",
      "Naive Bayes\n",
      "F1 score: 0.650792416843852\n",
      "Recall score: 0.673469387755102\n",
      "Precision score: 0.6839185895401485\n",
      "Accuracy score: 0.673469387755102 \n",
      "\n",
      "Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\willy.silva\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.828983768589426\n",
      "Recall score: 0.8367346938775511\n",
      "Precision score: 0.8364835811858878\n",
      "Accuracy score: 0.8367346938775511 \n",
      "\n",
      "Logistic Regression\n",
      "F1 score: 0.7290680430254465\n",
      "Recall score: 0.7397959183673469\n",
      "Precision score: 0.7625489590849929\n",
      "Accuracy score: 0.7397959183673469 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "print(\"SVM\")\n",
    "svm_predict = svm_model.predict(test_x)\n",
    "print(\"F1 score:\",f1_score(test_y, svm_predict, average='weighted'))\n",
    "print(\"Recall score:\",recall_score(test_y, svm_predict, average='weighted'))\n",
    "print(\"Precision score:\",precision_score(test_y, svm_predict, average='weighted'))\n",
    "print(\"Accuracy score:\",accuracy_score(test_y, svm_predict, normalize = True),'\\n')\n",
    "\n",
    "# Naive Bayers\n",
    "print(\"Naive Bayes\")\n",
    "nv_predict = nv_model.predict(test_x)\n",
    "print(\"F1 score:\",f1_score(test_y, nv_predict, average='weighted'))\n",
    "print(\"Recall score:\",recall_score(test_y, nv_predict, average='weighted'))\n",
    "print(\"Precision score:\",precision_score(test_y, nv_predict, average='weighted'))\n",
    "print(\"Accuracy score:\",accuracy_score(test_y, nv_predict, normalize = True),'\\n')\n",
    "\n",
    "# Random Forest\n",
    "print(\"Random Forest\")\n",
    "rf_predict = rf_model.predict(test_x)\n",
    "print(\"F1 score:\",f1_score(test_y, rf_predict, average='weighted'))\n",
    "print(\"Recall score:\",recall_score(test_y, rf_predict, average='weighted'))\n",
    "print(\"Precision score:\",precision_score(test_y, rf_predict, average='weighted'))\n",
    "print(\"Accuracy score:\",accuracy_score(test_y, rf_predict, normalize = True),'\\n')\n",
    "\n",
    "# Logistic Regression\n",
    "print(\"Logistic Regression\")\n",
    "lr_predict = lr_model.predict(test_x)\n",
    "print(\"F1 score:\",f1_score(test_y, lr_predict, average='weighted'))\n",
    "print(\"Recall score:\",recall_score(test_y, lr_predict, average='weighted'))\n",
    "print(\"Precision score:\",precision_score(test_y, lr_predict, average='weighted'))\n",
    "print(\"Accuracy score:\",accuracy_score(test_y, lr_predict, normalize = True),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3dfb64b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer',\n",
       "                 TfidfVectorizer(max_df=0.7, max_features=1500, min_df=5)),\n",
       "                ('svc',\n",
       "                 SVC(C=16, gamma='auto', kernel='linear', probability=True))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipeline = make_pipeline(vectorizer, svm_model)\n",
    "\n",
    "pipeline.fit(train_container.get_ementa(), train_container.get_assunto())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53d890d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(pipeline, open('pipeline.pickle', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
